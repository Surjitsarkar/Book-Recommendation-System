# -*- coding: utf-8 -*-
"""Book_Recommendation_System.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d-4p1xghFWl5SWLTijfIM769RnfzZTAO

**(1) Importing the libraries**
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

"""**(2) Importing the datasets**"""

books_dataset = pd.read_csv('books.csv', usecols=['id', 'book_id', 'books_count', 'isbn', 'authors', 'original_title', 'average_rating', 'ratings_count', 'work_ratings_count', 'ratings_1', 'ratings_2', 'ratings_3', 'ratings_4', 'ratings_5' ])
rating_dataset = pd.read_csv('ratings.csv', usecols=['book_id', 'user_id', 'rating'])

books_dataset.head()

print(books_dataset.shape)

rating_dataset.head()

"""**(3) Removing the duplicate row for column 'book_id', if there is any...**"""

new_books_dataset = books_dataset.drop_duplicates(subset = "book_id")
new_books_dataset.head()

print(new_books_dataset.shape)

"""**Note: Rating in rating_dataset in integer rather than float**

**(4) Depicting the rating graph for a book**
"""

b_id = int(input("Enter the book id= "))

id_ls = list(new_books_dataset.iloc[:,1:2].values)

print(id_ls)

i = id_ls.index(b_id)
print(i)

import numpy as np

if b_id in id_ls:

  #-----Finding out the range of rating 1-----

  rate1_range = new_books_dataset.iloc[i+1:i+2, 9:10].values

  print("RATE1:",rate1_range)

  RATE1 = (rate1_range)/100000

  print("\n --------------- \n")

  #-----Finding out the range of rating 2-----

  rate2_range = new_books_dataset.iloc[i+1:i+2, 10:11].values

  print("RATE2:",rate2_range)

  RATE2 = (rate2_range)/100000

  print("\n --------------- \n")

  #-----Finding out the range of rating 3-----

  rate3_range = new_books_dataset.iloc[i+1:i+2, 11:12].values

  print("RATE3:",rate3_range)

  RATE3 = (rate3_range)/100000

  print("\n --------------- \n")

  #-----Finding out the range of rating 4-----

  rate4_range = new_books_dataset.iloc[i+1:i+2, 12:13].values

  print("RATE4:",rate4_range)

  RATE4 = (rate4_range)/100000

  print("\n --------------- \n")

  #-----Finding out the range of rating 5-----

  rate5_range = new_books_dataset.iloc[i+1:i+2, 13:14].values

  print("RATE5:",rate5_range)

  RATE5 = (rate5_range)/100000

  print("\n --------------- \n")

  book_name = str(np.ravel(new_books_dataset.iloc[i+1:i+2, 5:6].values))

  print("Observing the count of rating of books", book_name)
  print("\n")

  ratings = {'1star' : RATE1, '2star' : RATE2, '3star' : RATE3, '4star' : RATE4, '5star' : RATE5}

  ratings_type = list(ratings.keys())
  ratings_values = list(ratings.values())


  #converting the 2d array into 1d array
  new_ratings_type = np.ravel(ratings_type)
  new_ratings_values = np.ravel(ratings_values)

  fig = plt.figure(figsize = (3, 5))

  plt.bar(new_ratings_type, new_ratings_values, color = 'blue', width= 0.4)


  plt.title('Rating count graph\n')
  plt.xlabel('Stars/Counts')
  plt.ylabel('Ratings in Lacs')
  plt.show()
  

else:
  print("No books with id",b_id,"is found in dataset")

"""**(5) Merging the Table of "userid", with Table of "new_books_dataset"**"""

merged_rating_dataset = pd.merge(new_books_dataset, rating_dataset, on='book_id')

merged_rating_dataset.head()

"""**(6) Filtering the books whose total ratings is less than 2500**

Here we will use the threshold value to decided the proper consdered ratings
"""

filter_threshold_value = 2500

new_rating_dataset = merged_rating_dataset.query('work_ratings_count >= @filter_threshold_value')

new_rating_dataset.head()

"""**(7) Drop down the column "rating" which is 'int', rather than 'float'**"""

#dropping the column

new_rating_dataset.drop(['rating'], axis=1, inplace=True)

new_rating_dataset.head()

new_rating_dataset.shape

"""**(8) Creating the Feature Pivot Matrix**"""

new_rating_dataset_df = new_rating_dataset.pivot_table(index = 'original_title', columns = 'user_id', values = 'average_rating').fillna(0)

new_rating_dataset_df.head()

from scipy.sparse import csr_matrix

rating_dataset_matrix = csr_matrix(new_rating_dataset_df.values)

"""**(9) Implementing the K-NN Algorithm**"""

from sklearn.neighbors import NearestNeighbors
KNN = NearestNeighbors(n_neighbors=5, metric='cosine', algorithm = 'brute')
KNN.fit(rating_dataset_matrix)

new_rating_dataset_df.shape

query_index = np.random.choice(new_rating_dataset_df.shape[0])
print(query_index)
distances, indices = KNN.kneighbors(new_rating_dataset_df.iloc[query_index,:].values.reshape(1, -1), n_neighbors = 6)

new_rating_dataset_df.head()

"""**(10) Final Recommendation using Cosine Similarity**"""

for i in range(0, len(distances.flatten())):
    if i == 0:
        print('Recommendations for {0}:\n'.format(new_rating_dataset_df.index[query_index]))
    else:
        print('{0}: {1}, with distance of {2}:'.format(i, new_rating_dataset_df.index[indices.flatten()[i]], distances.flatten()[i]))